We performed experiments with the models described in section \ref{sec:models}.

We performed classification experiments on LSA16, RWTH and CIARP handshape datasets. We used $k$-fold cross-validation \cite{Refaeilzadeh2009} randomly partitioning the original dataset into $k = 5$ equal sized subsamples.

For each subsample, we split the dataset in training and test sets, with the latter taking 25\% of the samples. The used splits were stratified, maintaining the proportion of samples of each class in both sets. At the same time, we define validation subsets for each training process. The sets are created with a number of samples per class of 20\% of the number of samples per class of the train set used in each scenario.

We performed experiments using the embedding architectures and configurations described in the following subsections varying the training sample sizes taking 5, 10, 15 and 20 samples, adding the scenarios of 30, 40 and 100 samples per class for CIARP and 30 and 40 for RWTH since they have a bigger amount of samples. In the case of RWTH, those classes that do not have at least 40 samples to carry out the training are filtered.

The same data augmentation was used for each experiment, with which the best results were obtained in previous works \cite{cornejo2019hand}. We applied normalization feature-wise subtracting the mean and dividing by the standard deviation of each feature. For data augmentation we used horizontal flipping,  random rotations from $0\deg$ to $10\deg$ and random resampling. The resampling is performed by reducing each image by 10\% or 20\% in width and height.

\subsection{Wide-DenseNet} \label{sec:experiments:densenet}

\subsubsection{Metodology}

Based on the results obtained in previous works \cite{cornejo2019hand}, we use DenseNet in the following way. We include SE blocks after each dense and transition block. We trained the models using a batch size of 32, an initial learning rate of $10^{-3}$ and 200 epochs with a maximum patience of 55. The resulting model used a growth rate of 64 and two dense blocks with 6 and 12 layers respectively, for all datasets.

\subsubsection{Results}

In tables \ref{tab:results:ciarp:densenet}, \ref{tab:results:lsa16:densenet} and \ref{tab:results:rwth:densenet} we can see the results obtained using Wide-Densenet on CIARP, LSA16 and RWTH, respectively. We can notice the low accuracy obtained in the subsets of 5 samples and how the accuracy increases when the number of samples is bigger.

The following sections compare the results obtained for each experiment with those obtained by Wide-DenseNet.

\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy obtained by Wide-DenseNet on CIARP as number of training samples is varied.} \label{tab:results:ciarp:densenet}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{8em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} }
\toprule
\emph{Method} & \emph{5 samples} & \emph{10 samples} &  \emph{15 samples} & \emph{20 samples} & \emph{30 samples} & \emph{40 samples} & \emph{100 samples} & \emph{360 samples} \\ \midrule

DenseNet           &   10.00 $\pm$ 0.00  &   10.00 $\pm$ 0.00  &   37.26 $\pm$ 36.81 &   76.07 $\pm$ 37.87 &   82.71 $\pm$ 38.35 &   99.83 $\pm$ 0.28  &   99.95 $\pm$ 0.04  &   99.83 $\pm$ 0.24  \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}


\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of Wide-DenseNet on LSA16 as number of training samples is varied.} \label{tab:results:lsa16:densenet}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{9em} p{7em} p{7em} p{7em} p{7em} p{7em} }
\toprule
\emph{Method} & \emph{5 samples} & \emph{10 samples} &  \emph{15 samples} & \emph{20 samples} & \emph{30 samples}   \\ \midrule

DenseNet           &    6.56 $\pm$ 0.63  &   92.80 $\pm$ 2.89  &   92.81 $\pm$ 2.82  &   95.31 $\pm$ 1.23  &   96.13 $\pm$ 0.00   \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}


\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of Wide-DenseNet on RWTH as number of training samples is varied.} \label{tab:results:rwth:densenet}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{9em} p{7em} p{7em} p{7em} p{7em} p{7em} p{7em} p{7em} }
\toprule
\emph{Method}   & \emph{5 samples}    & \emph{10 samples}   &  \emph{15 samples}  & \emph{20 samples}   & \emph{30 samples}   & \emph{40 samples}   & \emph{Full RWTH} \\ \midrule

DenseNet           &   10.32 $\pm$ 2.48  &   17.78 $\pm$ 17.08 &   46.66 $\pm$ 19.17 &   64.59 $\pm$ 3.81  &   71.20 $\pm$ 2.24  &   71.85 $\pm$ 3.84  &   96.05 $\pm$ 0.96 \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}

\subsection{Transfer Learning} \label{sec:experiments:tl}

\subsubsection{Metodology}

We performed experiments in every dataset to figure out which Transfer Learning configuration is more convenient. For each dataset, experiments are carried out varying the dataset on which the base model used to define the embedding architecture is trained. With this approach, it is possible to define an experiment matrix seeking to evaluate which dataset is the best option when transferring learning over another.

Our embedding architecture consists of a sequential model with a pretrained DenseNet model, global average pooling, a hidden dense layer with a ReLU nonlinearity and finally a softmax classifier. Since CIARP contains only gray scale images, an input layer and a 3x3 convolutional layer are prepended to the sequential model.

Furthermore, in this set of experiments CIFAR10\cite{cifar10dataset} and MNIST\cite{lecun-mnisthandwrittendigit-2010} are added to the datasets which are used for the construction of the pre-trained models.

\subsubsection{Results}

In tables \ref{tab:results:ciarp:tl}, \ref{tab:results:lsa16:tl} and \ref{tab:results:rwth:tl} we can see the results obtained using models trained with Transfer Learning on CIARP, LSA16 and RWTH, respectively. We can notice the low accuracy obtained in the subsets of 5 samples and how the accuracy increases when the number of samples is bigger.

In the case of CIARP, the use of transfer learning gives significantly better results than those obtained by Wide-DenseNet for those cases in which the number of training examples is less than 40, therefore the use of this method is advantageous. Considering this and the results obtained in LSA16, the use of Transfer Learning on those datasets means an advantage over the accuracy obtained by Wide-DenseNet model, however it is not so in the case of RWTH.

\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of various models trained using Transfer Learning on CIARP compared to the accuracy obtained by Wide-DenseNet. Each method named as \textit{TL + D} represents a transfer learning method using a model pretrained in \textit{D} dataset.} \label{tab:results:ciarp:tl}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{8em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} }
\toprule
\emph{Method} & \emph{5 samples} & \emph{10 samples} &  \emph{15 samples} & \emph{20 samples} & \emph{30 samples} & \emph{40 samples} & \emph{100 samples} & \emph{360 samples} \\ \midrule

DenseNet      &   10.00 $\pm$ 0.00  &   10.00 $\pm$ 0.00  &   37.26 $\pm$ 36.81 &   76.07 $\pm$ 37.87 &   82.71 $\pm$ 38.35 &   99.73 $\pm$ 0.28  &   99.95 $\pm$ 0.04  &   \textbf{99.83 $\pm$ 0.24}  \\
TL + CIFAR10  &   \textbf{11.69 $\pm$ 3.39}  &   \textbf{27.24 $\pm$ 33.54} &   98.44 $\pm$ 0.47  &   98.71 $\pm$ 0.72  &   \textbf{99.61 $\pm$ 0.21}  &   99.64 $\pm$ 0.31  &   99.92 $\pm$ 0.05  &   99.59 $\pm$ 0.19  \\
TL + MNIST    &   10.00 $\pm$ 0.00  &   10.00 $\pm$ 0.00  &   97.31 $\pm$ 1.36  &   \textbf{99.25 $\pm$ 0.37}  &   99.30 $\pm$ 0.48  &   99.70 $\pm$ 0.31  &   \textbf{99.95 $\pm$ 0.03}  &   99.21 $\pm$ 0.51  \\
TL + LSA16    &   11.19 $\pm$ 2.38  &   10.01 $\pm$ 0.02  &   97.82 $\pm$ 0.93  &   99.07 $\pm$ 0.45  &   99.51 $\pm$ 0.24  &   99.73 $\pm$ 0.33  &   99.93 $\pm$ 0.06  &   99.73 $\pm$ 0.26  \\
TL + RWTH     &   10.24 $\pm$ 0.49  &   10.03 $\pm$ 0.04  &   \textbf{98.59 $\pm$ 0.83}  &   98.33 $\pm$ 1.16  &   99.58 $\pm$ 0.20  &   \textbf{99.74 $\pm$ 0.16}  &   99.85 $\pm$ 0.09  &   99.42 $\pm$ 0.40  \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}


\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of various models trained using Transfer Learning on LSA16 compared to the accuracy obtained by Wide-DenseNet. Each method named as \textit{TL + D} represents a transfer learning method using a model pretrained in \textit{D} dataset.} \label{tab:results:lsa16:tl}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{9em} p{7em} p{7em} p{7em} p{7em} p{7em} }
\toprule
\emph{Method} & \emph{5 samples} & \emph{10 samples} &  \emph{15 samples} & \emph{20 samples} & \emph{30 samples}   \\ \midrule

DenseNet           &    6.56 $\pm$ 0.63  &   92.80 $\pm$ 2.89  &   92.81 $\pm$ 2.82  &   95.31 $\pm$ 1.23  &   96.13 $\pm$ 0.00   \\
TL + CIFAR10       &    6.25 $\pm$ 0.00  &   \textbf{92.91 $\pm$ 2.66}  &   \textbf{93.75 $\pm$ 2.30}  &   94.79 $\pm$ 1.14  &   \textbf{97.91 $\pm$ 0.46}   \\
TL + MNIST         &    6.25 $\pm$ 0.00  &   92.60 $\pm$ 2.07  &   93.43 $\pm$ 1.73  &   95.41 $\pm$ 2.42  &   97.08 $\pm$ 0.62   \\
TL + CIARP         &    6.25 $\pm$ 0.00  &   92.70 $\pm$ 1.77  &   92.60 $\pm$ 1.87  &   \textbf{96.67 $\pm$ 1.12}  &   96.24 $\pm$ 1.48   \\
TL + RWTH          &    \textbf{6.97 $\pm$ 1.45}  &   74.79 $\pm$ 34.27 &   93.43 $\pm$ 2.56  &   95.62 $\pm$ 1.21  &   96.97 $\pm$ 0.89   \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}


\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of various models trained using Transfer Learning on RWTH compared to the accuracy obtained by Wide-DenseNet. Each method named as \textit{TL + D} represents a transfer learning method using a model pretrained in \textit{D} dataset.} \label{tab:results:rwth:tl}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{9em} p{7em} p{7em} p{7em} p{7em} p{7em} p{7em} p{7em} }
\toprule
\emph{Method}   & \emph{5 samples}    & \emph{10 samples}   &  \emph{15 samples}  & \emph{20 samples}   & \emph{30 samples}   & \emph{40 samples}   & \emph{Full RWTH} \\ \midrule

DenseNet        &   10.32 $\pm$ 2.48  &   17.78 $\pm$ 17.08 &   \textbf{46.66 $\pm$ 19.17} &   \textbf{64.59 $\pm$ 3.81}  &   \textbf{71.20 $\pm$ 2.24}  &   \textbf{71.85 $\pm$ 3.84}  &   \textbf{96.05 $\pm$ 0.96} \\
TL + CIFAR10    &   \textbf{10.73 $\pm$ 1.59}  &   17.78 $\pm$ 17.21 &   18.25 $\pm$ 16.33 &   48.19 $\pm$ 21.08 &   65.76 $\pm$ 6.50  &   66.28 $\pm$ 4.67  &   95.29 $\pm$ 1.22   \\
TL + MNIST      &    9.89 $\pm$ 1.49  &   17.32 $\pm$ 15.89 &   21.12 $\pm$ 18.70 &   37.13 $\pm$ 24.93 &   64.91 $\pm$ 3.54  &   63.66 $\pm$ 3.86  &   96.16 $\pm$ 0.58   \\
TL + CIARP      &    9.31 $\pm$ 1.90  &   \textbf{18.30 $\pm$ 16.49} &   25.79 $\pm$ 21.30 &   39.07 $\pm$ 24.93 &   64.26 $\pm$ 5.42  &   66.69 $\pm$ 3.15  &   95.57 $\pm$ 1.06   \\
TL + LSA16      &    8.33 $\pm$ 0.00  &   17.15 $\pm$ 15.69 &   28.93 $\pm$ 24.06 &   46.22 $\pm$ 20.08 &   66.58 $\pm$ 5.00  &   62.89 $\pm$ 10.14 &   95.48 $\pm$ 0.30  \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}

\subsection{Model-Agnostic Meta-Learning}

\subsubsection{Metodology}

We employed the Wide-DenseNet architecture explained before \ref{sec:experiments:densenet} applying the Model-Agnostic Meta-Learning technique to the training process. In the work of Finn et al. \cite{DBLP:journals/corr/FinnAL17} they follow the experimental protocol proposed by Vinyals et al. \cite{DBLP:journals/corr/VinyalsBLKW16}, which involves fast learning of N-way classification with 1 or 5 shots. This is the protocol that we used for Prototypical Networks but not for the set of experiments that we propose in this section.

In this case, we test the performance of MAML applied to training scenarios similar to those used with Wide-DenseNet in the experiments described in section \ref{sec:experiments:densenet}, so the training process will work with batches in the following way. We trained a Wide-DenseNet model using the MAML technique over one task before doing the meta-learning. That task will correspond to short training process on a \textit{D} dataset following the process described in section \ref{sec:models:maml} . Then we use the trained model to initialize the weights for a new model. The new model is treated as a new task. Our model was trained on one task and we used this previous knowledge to initialize the weights of the model for a new task, using a training process similar to the used for the experiments we performed using Transfer Learning described in section \ref{sec:experiments:tl}.

\subsubsection{Results}

In tables \ref{tab:results:ciarp:maml}, \ref{tab:results:lsa16:maml} and \ref{tab:results:rwth:maml} we can see the results obtained using models trained with MAML technique on CIARP, LSA16 and RWTH, respectively. Again, we can see the low accuracy obtained in the subsets of 5 samples and how the accuracy increases when the number of samples is bigger.

In the case of CIARP, the use of MAML gives significantly better results than those obtained by Wide-DenseNet for those cases in which the number of training examples is less than 40, therefore the use of this method is advantageous. Considering this and the results obtained in LSA16, the use of Transfer Learning on those datasets means an advantage over the accuracy obtained by Wide-DenseNet model, however it is not so in the case of RWTH. \\

\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of various models trained using Model-Agnostic Meta-Learning on CIARP compared to the accuracy obtained by Wide-DenseNet. Each method named as \textit{MAML + D} represents a MAML method using a model pretrained in \textit{D} dataset.} \label{tab:results:ciarp:maml}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{8em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} }
\toprule
\emph{Method} & \emph{5 samples} & \emph{10 samples} &  \emph{15 samples} & \emph{20 samples} & \emph{30 samples} & \emph{40 samples} & \emph{100 samples} & \emph{360 samples} \\ \midrule

DenseNet           &   10.00 $\pm$ 0.00  &   10.00 $\pm$ 0.00  &   37.26 $\pm$ 36.81 &   76.07 $\pm$ 37.87 &   82.71 $\pm$ 38.35 &   99.83 $\pm$ 0.28  &   99.95 $\pm$ 0.04  &   \textbf{99.83 $\pm$ 0.24}  \\
MAML               &   11.12 $\pm$ 2.24  &   \textbf{26.53 $\pm$ 33.07} &   80.23 $\pm$ 35.13 &   98.85 $\pm$ 0.99  &   99.71 $\pm$ 0.15  &   99.56 $\pm$ 0.34  &   99.94 $\pm$ 0.04  &   99.01 $\pm$ 0.66  \\
MAML + CIFAR10     &   10.47 $\pm$ 0.94  &   10.00 $\pm$ 0.00  &   95.51 $\pm$ 2.15  &   98.41 $\pm$ 1.16  &   \textbf{99.73 $\pm$ 0.30}  &   98.92 $\pm$ 1.72  &   99.96 $\pm$ 0.02  &   99.44 $\pm$ 0.38  \\
MAML + MNIST       &   10.00 $\pm$ 0.00  &   12.70 $\pm$ 3.27  &   80.13 $\pm$ 35.07 &   98.91 $\pm$ 0.47  &   99.64 $\pm$ 0.16  &   \textbf{99.74 $\pm$ 0.16}  &   99.97 $\pm$ 0.04  &   99.43 $\pm$ 0.64  \\
MAML + LSA16       &   \textbf{11.38 $\pm$ 2.65}  &   11.44 $\pm$ 2.49  &   80.10 $\pm$ 35.07 &   98.95 $\pm$ 0.64  &   99.51 $\pm$ 0.45  &   99.50 $\pm$ 0.62  &   99.93 $\pm$ 0.08  &   99.30 $\pm$ 0.61  \\
MAML + RWTH        &   10.00 $\pm$ 0.00  &   10.00 $\pm$ 0.00  &   \textbf{97.75 $\pm$ 0.52}  &   \textbf{99.07 $\pm$ 0.63}  &   99.64 $\pm$ 0.18  &   99.65 $\pm$ 0.17  &   \textbf{99.97 $\pm$ 0.02}  &   99.08 $\pm$ 0.73  \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}

\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of various models trained using Model-Agnostic Meta-Learning on LSA16 compared to the accuracy obtained by Wide-DenseNet. Each method named as \textit{MAML + D} represents a MAML method using a model pretrained in \textit{D} dataset.} \label{tab:results:lsa16:maml}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{9em} p{7em} p{7em} p{7em} p{7em} p{7em} }
\toprule
\emph{Method} & \emph{5 samples} & \emph{10 samples} &  \emph{15 samples} & \emph{20 samples} & \emph{30 samples}   \\ \midrule

DenseNet           &    6.56 $\pm$ 0.63  &   92.80 $\pm$ 2.89  &   92.81 $\pm$ 2.82  &   95.31 $\pm$ 1.23  &   96.13 $\pm$ 0.00   \\
MAML               &    6.35 $\pm$ 0.20  &   \textbf{93.95 $\pm$ 1.53}  &   93.54 $\pm$ 1.60  &   95.72 $\pm$ 1.00  &   \textbf{97.81 $\pm$ 0.38}   \\
MAML + CIFAR10     &    6.25 $\pm$ 0.00  &   92.18 $\pm$ 1.47  &   94.06 $\pm$ 1.76  &   95.63 $\pm$ 2.60  &   97.08 $\pm$ 0.77   \\
MAML + MNIST       &    6.45 $\pm$ 0.41  &   92.91 $\pm$ 0.96  &   94.17 $\pm$ 2.45  &   95.63 $\pm$ 1.16  &   97.18 $\pm$ 0.41   \\
MAML + CIARP       &    6.77 $\pm$ 0.65  &   92.08 $\pm$ 2.51  &   \textbf{94.58 $\pm$ 1.16}  &   \textbf{96.14 $\pm$ 1.34}  &   96.97 $\pm$ 1.25   \\
MAML + RWTH        &    \textbf{6.87 $\pm$ 0.76}  &   92.81 $\pm$ 0.51  &   94.47 $\pm$ 2.29  &   94.37 $\pm$ 2.58  &   96.24 $\pm$ 1.00   \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}

\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of various models trained using Model-Agnostic Meta-Learning on RWTH compared to the accuracy obtained by Wide-DenseNet. Each method named as \textit{MAML + D} represents a MAML method using a model pretrained in \textit{D} dataset.} \label{tab:results:rwth:maml}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{9em} p{7em} p{7em} p{7em} p{7em} p{7em} p{7em} p{7em} }
\toprule
\emph{Method}   & \emph{5 samples}    & \emph{10 samples}   &  \emph{15 samples}  & \emph{20 samples}   & \emph{30 samples}   & \emph{40 samples}   & \emph{Full RWTH} \\ \midrule

DenseNet           &   10.32 $\pm$ 2.48  &   \textbf{17.78 $\pm$ 17.08} &   \textbf{46.66 $\pm$ 19.17} &   \textbf{64.59 $\pm$ 3.81}  &   \textbf{71.20 $\pm$ 2.24}  &   \textbf{71.85 $\pm$ 3.84}  &   \textbf{96.05 $\pm$ 0.96} \\
MAML               &    9.20 $\pm$ 1.97  &    9.86 $\pm$ 1.29  &   25.38 $\pm$ 19.31 &   30.51 $\pm$ 24.03 &   67.81 $\pm$ 1.99  &   67.13 $\pm$ 1.55  &   95.54 $\pm$ 1.21   \\
MAML + CIFAR10     &    8.36 $\pm$ 0.62  &    9.69 $\pm$ 1.94  &    8.66 $\pm$ 1.75  &   38.90 $\pm$ 24.40 &   64.56 $\pm$ 7.86  &   64.53 $\pm$ 3.18  &   96.08 $\pm$ 0.37   \\
MAML + MNIST       &    9.80 $\pm$ 1.27  &    9.80 $\pm$ 2.03  &   28.33 $\pm$ 21.66 &   51.12 $\pm$ 21.42 &   66.93 $\pm$ 3.13  &   69.07 $\pm$ 4.66  &   95.73 $\pm$ 0.56   \\
MAML + CIARP       &    9.83 $\pm$ 2.80  &   17.59 $\pm$ 16.62 &   19.15 $\pm$ 18.97 &   38.57 $\pm$ 23.35 &   66.50 $\pm$ 3.05  &   66.36 $\pm$ 3.02  &   96.00 $\pm$ 0.35   \\
MAML + LSA16       &   \textbf{10.98 $\pm$ 3.66}  &   15.16 $\pm$ 11.85 &   28.57 $\pm$ 23.10 &   46.96 $\pm$ 19.03 &   67.18 $\pm$ 4.49  &   64.42 $\pm$ 3.58  &   95.48 $\pm$ 1.29   \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}

\subsection{Prototypical Network}

As mentioned in section \ref{models:protonet}, we can use Prototypical Networks' ability to work with small datasets even if all samples are labeled. Based on the results obtained in previous works \cite{cornejo2019hand}, we use Prototypical Networks with the following configuration.

\subsubsection{Metodology}

Our Prototypical Networks employ an embedding architecture composed of four convolutional blocks. Each block comprises a 64-filter $3 \times 3$ convolution, followed by a batch normalization layer, a ReLU nonlinearity and $2 x 2$ max-pooling.

We used the same encoder for embedding both support and query points. All of our models were trained with the ADAM\cite{Adam} optimizer. We used an initial learning rate of $10^{-3}$ and cut the learning rate in half every $2000$ episodes.

We trained the networks using Euclidean distance in the 1-shot and 5-shot scenarios with training episodes containing 16, 20 and 10 classes (for LSA16, RWTH and CIARP respectively) and 5 query points per class when possible. We computed classification accuracy for our models by averaging over 1000 randomly generated episodes from the test set.

In previous works \cite{cornejo2019hand}, we found that the difference in the results obtained in 1-shot and 5-shot scenarios for these datasets was very large. On the other hand, 5-shot scenarios gave better results. Therefore, we only used 1-shot learning in the experiments in which the minimum number of examples per class does not allow to use 5-shot.

\subsubsection{Results}

In tables \ref{tab:results:ciarp:proto}, \ref{tab:results:lsa16:proto} and \ref{tab:results:rwth:proto} we can see the results obtained using models trained with MAML technique on CIARP, LSA16 and RWTH, respectively. 

Prototypical Networks have similar accuracy for LSA16 and CIARP datasets beating the Wide-DenseNet models for the 5 and 10 samples scenarios, and also the other splits in the case of LSA16. In the case of CIARP, although it did not obtain the best results for all subsets, it achieved a very good performance in all cases, and similar results for the obtained by Wide-DenseNet.

Regarding RWTH, we can notice that Prototypical Networks cannot take advantage of the images and the accuracy does not increase as the number of samples do. It is possible that Prototypical Networks obtained the lowest accuracy because the images of the hands were unsegmented. In this case, the accuracy of Wide-DenseNet is slightly bigger than Prototypical Networks model when the number of samples per class, N, is bigger than 15.

\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of Prototypical Networks based model on CIARP compared to the accuracy obtained by Wide-DenseNet.} \label{tab:results:ciarp:proto}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{8em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} p{6em} }
\toprule
\emph{Method} & \emph{5 samples} & \emph{10 samples} &  \emph{15 samples} & \emph{20 samples} & \emph{30 samples} & \emph{40 samples} & \emph{100 samples} & \emph{360 samples} \\ \midrule

DenseNet           &   10.00 $\pm$ 0.00  &   10.00 $\pm$ 0.00  &   37.26 $\pm$ 36.81 &   76.07 $\pm$ 37.87 &   82.71 $\pm$ 38.35 &   99.83 $\pm$ 0.28  &   \textbf{99.95 $\pm$ 0.04}  &   \textbf{99.83 $\pm$ 0.24}  \\
ProtoNet           &   \textbf{91.45 $\pm$ 2.44}  &   \textbf{94.48 $\pm$ 1.78}  &   \textbf{95.70 $\pm$ 0.66}  &   \textbf{97.63 $\pm$ 0.68}  &   \textbf{98.38 $\pm$ 0.27}  &   \textbf{99.21 $\pm$ 0.28}  &   99.82 $\pm$ 0.05  &   99.41 $\pm$ 0.16  \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}

\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of Prototypical Networks based model on LSA16 compared to the accuracy obtained by Wide-DenseNet.} \label{tab:results:lsa16:proto}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{9em} p{7em} p{7em} p{7em} p{7em} p{7em} }
\toprule
\emph{Method} & \emph{5 samples} & \emph{10 samples} &  \emph{15 samples} & \emph{20 samples} & \emph{30 samples}   \\ \midrule

DenseNet           &    6.56 $\pm$ 0.63  &   92.80 $\pm$ 2.89  &   92.81 $\pm$ 2.82  &   95.31 $\pm$ 1.23  &   96.13 $\pm$ 0.00   \\
ProtoNet           &   \textbf{94.15 $\pm$ 1.27}  &   \textbf{94.64 $\pm$ 1.23}  &   \textbf{95.50 $\pm$ 1.01}  &   \textbf{97.20 $\pm$ 0.74}  &   \textbf{98.38 $\pm$ 0.22}   \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}

\doublerulesep 0.1pt
\begin{table*}[!ht]
\begin{footnotesize}
\caption{Accuracy of Prototypical Networks based model on RWTH compared to the accuracy obtained by Wide-DenseNet.} \label{tab:results:rwth:proto}
\makebox[1 \textwidth][c]{
\centering
\begin{tabular}{ p{9em} p{7em} p{7em} p{7em} p{7em} p{7em} p{7em} p{7em} }
\toprule
\emph{Method}   & \emph{5 samples}    & \emph{10 samples}   &  \emph{15 samples}  & \emph{20 samples}   & \emph{30 samples}   & \emph{40 samples}   & \emph{Full RWTH} \\ \midrule

DenseNet           &   10.32 $\pm$ 2.48  &   17.78 $\pm$ 17.08 &   46.66 $\pm$ 19.17 &   \textbf{64.59 $\pm$ 3.81}  &   \textbf{71.20 $\pm$ 2.24}  &   \textbf{71.85 $\pm$ 3.84}  &   \textbf{96.05 $\pm$ 0.96} \\
ProtoNet           &   \textbf{48.93 $\pm$ 3.02}  &   \textbf{48.53 $\pm$ 1.59}  &   \textbf{48.87 $\pm$ 1.60}  &   46.73 $\pm$ 1.14  &   47.58 $\pm$ 1.33  &   50.36 $\pm$ 6.82  &   47.09 $\pm$ 0.10   \\

\bottomrule
\end{tabular}
} %close centering
\end{footnotesize}
\end{table*}

